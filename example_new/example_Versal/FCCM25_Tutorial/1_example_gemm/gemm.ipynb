{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§® GEMM Example\n",
    "\n",
    "In this example, we perform a General Matrix Multiplication (GEMM) on input matrices `A` and `B` to compute the result matrix `C`. The algorithm follows the standard GEMM formula:\n",
    "\n",
    "```\n",
    "C[i, j] += A[i, k] * B[k, j]\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point to the ARIES frontend directory and import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cur_dir = os.getcwd()\n",
    "aries_path = cur_dir + \"/../../../../\"\n",
    "sys.path.append(aries_path)\n",
    "from frontend import *\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the entire workload and specify the tile size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMM: C[i0, j0] += A[i0, k0] * B[k0, j0]\n",
    "I, J, K = 256, 256, 256\n",
    "TI, TJ, TK = 32, 32, 32\n",
    "grid = (I // TI, J // TJ, K // TK)  # grid must be a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the GEMM operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_kernel()\n",
    "def kernel_gemm(TileA: float32[TI, TK], \n",
    "                TileB: float32[TK, TJ], \n",
    "                TileC: float32[TI, TJ]):\n",
    "    for i0 in range(0, TI):\n",
    "        for j0 in range(0, TJ):\n",
    "            TileC[i0, j0] = float32(0)\n",
    "            for k0 in range(0, TK):\n",
    "                TileC[i0, j0] += TileA[i0, k0] * TileB[k0, j0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiled Programming Model in ARIES\n",
    "\n",
    "In ARIES, the computation is structured using a **tiled programming model**. The channels between L3 and L1 are unidirectional, meaning they support only either loading or storing. It is recommended to perform constant initialization within a single kernel whenever possible tp save the number of channel.\n",
    "\n",
    "<img src=\"../images/gemm.png\" alt=\"GEMM\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory arguments defined in @task_tile represent L3 memory. This decorator primarily handles local memory allocation and describes data movement between L3 and L1 memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_tile()\n",
    "def gemm(A: float32[I, K], B: float32[K, J], \n",
    "         C: float32[I, J], **kwargs):\n",
    "    i, j, k = aries.tile_ranks(**kwargs)\n",
    "    \n",
    "    L1_A = aries.buffer((TI, TK), \"float32\")\n",
    "    L1_B = aries.buffer((TK, TJ), \"float32\")\n",
    "    L1_C = aries.buffer((TI, TJ), \"float32\")\n",
    "    \n",
    "    \n",
    "    ############## Please fill the logic of ti and tk #################\n",
    "    \n",
    "    # Slice data using aries.arrage(start, stop)\n",
    "    ti =\n",
    "    tk =\n",
    "    \n",
    "    ####################################################################\n",
    "    tj = aries.arange(j*TJ, (j+1)*TJ)  # J tile range\n",
    "    \n",
    "    \n",
    "    L1_A = aries.load(A, (ti, tk))\n",
    "    L1_B = aries.load(B, (tk, tj))\n",
    "    kernel_gemm(L1_A, L1_B, L1_C)\n",
    "    aries.accstore(L1_C, C, (ti, tj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Answer (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "ti = aries.arange(i*TI, (i+1)*TI)  # I tile range  \n",
    "tk = aries.arange(k*TK, (k+1)*TK)  # K tile range\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define top function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_top()\n",
    "def top(A: float32[I, K], B: float32[K, J], C: float32[I, J]):\n",
    "    gemm_task = gemm[grid](A, B, C)\n",
    "    return gemm_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input cells that contains the decorators\n",
    "cell_codes = get_ipython().user_ns[\"In\"][2:6]\n",
    "# Join them into one string, with a newline between each cell\n",
    "all_code = \"\\n\".join(cell_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify correctness of AIRES program in frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the buffers\n",
    "np.random.seed(0)\n",
    "A = np.random.rand(I, K).astype(np.float32)\n",
    "B = np.random.rand(K, J).astype(np.float32)\n",
    "C = np.zeros((I, J)).astype(np.float32)\n",
    "\n",
    "# Execute on CPU\n",
    "gemm_task = top(A, B, C)\n",
    "golden_C = np.matmul(A, B)\n",
    "\n",
    "# Compare the program with golden file\n",
    "print(\"ARIES gemm output matches golden reference:\", np.allclose(C, golden_C))\n",
    "\n",
    "# Generate files for on-board test\n",
    "aries.gen_sim([A, B, golden_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply scheduling using **ARIES primitives**. In this example, the primitives are passed to the **AIE auto-vectorizer** provided by the **MLIR-AIE/IRON** project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply schedulings\n",
    "sch = Schedule(gemm_task)\n",
    "sch.to(\"VCK190\")\n",
    "\n",
    "# This is used in MLIR-AIE Auto Vectorizer for single AIE optimization\n",
    "sch.aieUnroll(gemm_task, factor=8) # Under the innermost loop by 8 times to improve pipeline efficency and guarantee memory aligment\n",
    "sch.aieVector(gemm_task, factor=8) # Automatically detect a suitable loop and perform vectorization (j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project dir and template dir\n",
    "prj_dir= cur_dir + '/project_gemm'\n",
    "temp_dir= aries_path + '/templates'\n",
    "# Generate Initial MLIR and ARIES Opts\n",
    "sch.build(all_code, prj_dir, temp_dir)\n",
    "sch.compile(aries_path, prj_dir, target=\"report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> AIE Design Diagram (click to expand)</summary>\n",
    "\n",
    "The AIE graph can be found under ```project_gemm/project/Work/reports/adf_graph_mapped_post.png```\n",
    "\n",
    "\n",
    "<div style=\"display: flex; gap: 100px;\">\n",
    "  <img src=\"../images/adf_graph_mapped_post.png\" alt=\"ADF Graph\" width=\"250\"/>\n",
    "  <img src=\"../images/gemm_aie.png\" alt=\"GEMM AIE\" width=\"250\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> AIE Profile Result - Vendor Tools (click to expand)</summary>\n",
    "\n",
    "**Theoretical Cycle Count for Kernel**: (32 Ã— 32 Ã— 32) / 8 = **4096 cycles**  \n",
    "**Measured Efficiency**: 4096 / 12756 â‰ˆ **32.1%**\n",
    "\n",
    "<img src=\"../images/gemm0_cycle.png\" alt=\"GEMM0 Cycle\" width=\"600\"/>\n",
    "<img src=\"../images/gemm0_cycle_name.png\" alt=\"GEMM0 Func Name\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Pipeline of Auto-Vectorized Single AIE (click to expand)</summary>\n",
    "\n",
    "The diagram below illustrates the pipeline of a single AIE (with size 2 x 4 x 8) generated by the **MLIR-AIE automatic vectorizer**, showcasing how operations are arranged for **VLIW** execution. On AIE-V1, the MAC operation with FP32 data type has a minimum latency of two cycles, which prevents accumulation into the same register on every cycle. The computation efficency will be less than 50%.\n",
    "\n",
    "<img src=\"../images/gemm_kernel.png\" alt=\"GEMM\" width=\"600\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
